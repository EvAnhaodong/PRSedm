{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "300843ed-0ea9-4032-b3df-59cf8c1c6aaa",
   "metadata": {},
   "source": [
    "# PRS for WGS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60c37ee-d08c-4631-b4b5-a9895812ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up Hail requirements on instance\n",
    "import os\n",
    "os.system('wget https://github.com/adoptium/temurin21-binaries/releases/download/jdk-21.0.4%2B7/OpenJDK21U-jre_x64_linux_hotspot_21.0.4_7.tar.gz')\n",
    "!tar -xvzf OpenJDK21U-jre_x64_linux_hotspot_21.0.4_7.tar.gz\n",
    "!pip install pyspark\n",
    "# Set the JAVA_HOME environment variable\n",
    "os.environ['JAVA_HOME'] = '/opt/notebooks/jdk-21.0.4+7-jre' \n",
    "os.environ['PATH'] = f\"{os.environ['JAVA_HOME']}/bin:\" + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9abe702-3c72-4ed8-a45a-ac446611eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up HAIL\n",
    "!pip install hail --force-reinstall\n",
    "import hail as hl\n",
    "\n",
    "hl.init(\n",
    "    master='local[*]',  # Use all available cores\n",
    "    spark_conf={\n",
    "        'spark.executor.memory': '4g',  # Adjust memory as needed\n",
    "        'spark.driver.memory': '4g'      # Adjust memory as needed\n",
    "    }\n",
    ")\n",
    "hl.default_reference('GRCh38')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f79eee-4f86-4575-b3ba-5c9945ef9728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download corresponding .vcf.gz block WGS file for each SNP into instance\n",
    "import os\n",
    "os.system('dx download <file_name.vcf.gz>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f333b2b-9feb-4d0d-ab00-2f75febd41f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download PRSedm into instance\n",
    "import os\n",
    "os.system('wget https://files.pythonhosted.org/packages/6e/d9/ebd00d933502674a1072f226bc429e5092ab365941262def01f4cffdbb44/prsedm-1.0.0-py3-none-any.whl')\n",
    "!pip install prsedm\n",
    "import prsedm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc8ba8-e5bc-46d2-b0a0-9bf08f196cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cryptography\n",
    "import OpenSSL\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "for chromosome in range(1, 23):  #Loop through chromosomes with * representing block number\n",
    "    vcf_file = f'<file_name_c{chromosome}_b*_v1.vcf.gz>'\n",
    "    print(f\"Importing {vcf_file} into Hail...\")\n",
    "    \n",
    "    try:\n",
    "        #Import into Hail\n",
    "        mt = hl.import_vcf(vcf_file, reference_genome='GRCh38', force_bgz=True)\n",
    "        print(f\"{vcf_file} imported successfully.\")\n",
    "\n",
    "        #Get list of SNPs to extract from PRS model\n",
    "        df = prsedm.get_snp_db('t1dgrs2-sharp24')\n",
    "        df = df.drop_duplicates().reset_index(drop=True)\n",
    "        \n",
    "        #Build a list of variant positions to extract\n",
    "        pos_col = 'position_hg38'  # change to hg19 if required\n",
    "        variantIntervals = [\n",
    "            f\"chr{row['contig_id']}:{row[pos_col]}-{row[pos_col] + 1}\"\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "        print(f\"Number of unique variants to extract: {len(variantIntervals)}\")\n",
    "\n",
    "        #Chunk up the regions incase there are too many variants requested\n",
    "        print(f\"Retrieve chunks from chromosome {chromosome} VCF and densify...\")\n",
    "        chunk_size = 1000\n",
    "        chunked_intervals = [variantIntervals[i:i + chunk_size] for i in range(0, len(variantIntervals), chunk_size)]\n",
    "        mt_subsets = []  # Reset subsets list for each chromosome\n",
    "        \n",
    "        for i, chunk in enumerate(chunked_intervals):\n",
    "            print(f\"Processing chunk {i + 1} for chromosome {chromosome}...\")\n",
    "            vcf_filtered = hl.filter_intervals(mt, [hl.parse_locus_interval(x) for x in chunk])\n",
    "            vcf_filtered = hl.split_multi_hts(vcf_filtered)\n",
    "            mt_subsets.append(vcf_filtered)\n",
    "        \n",
    "        #Combine chunks\n",
    "        print(f\"Combining retrieved chunks for chromosome {chromosome}...\")\n",
    "        if mt_subsets:\n",
    "            combined_mt = mt_subsets[0]\n",
    "            for mt_n in mt_subsets[1:]:\n",
    "                combined_mt = combined_mt.union_rows(mt_n)\n",
    "\n",
    "            #Process the merged data\n",
    "            print(f\"Processing merged MT for chromosome {chromosome}...\")\n",
    "            combined_mt = hl.variant_qc(combined_mt)\n",
    "            combined_mt = combined_mt.annotate_rows(info=hl.struct(AF=combined_mt.variant_qc.AF))\n",
    "\n",
    "            # Export to VCF\n",
    "            print(f\"Exporting chromosome {chromosome} to VCF...\")\n",
    "            start = datetime.now()\n",
    "            output_vcf = f'./chr{chromosome}_data_temp.vcf.bgz'\n",
    "            hl.export_vcf(combined_mt, output_vcf)\n",
    "            print(f\"Export for chromosome {chromosome} took {(datetime.now() - start).total_seconds():.2f} seconds\")\n",
    "        else:\n",
    "            print(f\"No MatrixTables were imported for chromosome {chromosome}; nothing to combine.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error importing or processing chromosome {chromosome} VCF: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b9b92f-2094-4541-aa8e-6fe4aae0319f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Use bcftools to merge VCF files\n",
    "!bcftools concat -n -Oz \\\n",
    "chr1_data_temp.vcf.bgz \\\n",
    "chr2_data_temp.vcf.bgz \\\n",
    "chr4_data_temp.vcf.bgz \\\n",
    "chr6_data_temp.vcf.bgz \\\n",
    "chr7_data_temp.vcf.bgz \\\n",
    "chr9_data_temp.vcf.bgz \\\n",
    "chr10_data_temp.vcf.bgz \\\n",
    "chr11_data_temp.vcf.bgz \\\n",
    "chr12_data_temp_1.vcf.bgz \\\n",
    "chr12_data_temp_2.vcf.bgz \\\n",
    "chr12_data_temp_3.vcf.bgz \\\n",
    "chr12_data_temp_4.vcf.bgz \\\n",
    "chr13_data_temp.vcf.bgz \\\n",
    "chr14_data_temp.vcf.bgz \\\n",
    "chr15_data_temp.vcf.bgz \\\n",
    "chr16_data_temp.vcf.bgz \\\n",
    "chr18_data_temp.vcf.bgz \\\n",
    "chr19_data_temp.vcf.bgz \\\n",
    "chr20_data_temp.vcf.bgz \\\n",
    "chr21_data_temp.vcf.bgz \\\n",
    "chr22_data_temp.vcf.bgz \\\n",
    " -o merged_wgs_data.vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc284711-7db5-44bf-b74a-a4b612d6c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index file\n",
    "!tabix -fp vcf merged_wgs_data.vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa303eb-65d9-4100-85ec-020d7de97641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download reference TOPMED data using command for individual account and then \n",
    "#Index files\n",
    "!for f in reference.vcf.gz;do tabix -f $f;done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f324720b-1434-48f2-a595-a3140fcff543",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Generate GRS\n",
    "output = prsedm.gen_dm(vcf=vcf, \n",
    "                            col=\"GT\", \n",
    "                            build=\"hg38\", \n",
    "                            prsflags=\"t1dgrs2-luckett25\", \n",
    "                            impute=1, \n",
    "                            refvcf=<path to TOPMED reference files>,\n",
    "                            norm=1,\n",
    "                            ntasks=16,\n",
    "                            parallel=1,\n",
    "                            batch_size=1)\n",
    "#Save results\n",
    "output.to_csv(f\"prsedm_result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
